{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e927453b",
   "metadata": {},
   "source": [
    "## Подключение всех необходимых библиотек"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 19,
>>>>>>> main
   "id": "659dba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch.functional import F\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torchaudio\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a478508",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "cee6314b",
=======
   "execution_count": 20,
   "id": "727bd37c",
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 22050\n",
    "AUDIO_TIME_SECONDS = 4.6  # median of all recording durations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32041f",
   "metadata": {},
   "source": [
    "# Обработка аудио файлов и создание csv файла (датасета) с признаками"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
   "id": "4e4e2c4d",
=======
   "execution_count": 21,
   "id": "938e4790",
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = pd.read_csv(\"train_gt (1).csv\")\n",
    "header = \"melspectrogram\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b624dcc",
   "metadata": {},
   "source": [
    "## 1. Заполнение csv файла данными"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 23,
>>>>>>> main
   "id": "a3175f6d",
   "metadata": {
    "scrolled": false
   },
<<<<<<< HEAD
=======
   "outputs": [],
   "source": [
    "if not os.path.exists(\"train_dataset.csv\") or \\\n",
    "    pd.read_csv(\"train_dataset.csv\").shape[1] - (6 + 1 + 1) != N_MFCCS: # other features + name + label\n",
    "    for folder in [\"train\", \"test\"]:\n",
    "        columns = (header if folder == \"test\" else header + \" label\").split()\n",
    "        features = pd.DataFrame(columns=columns)\n",
    "        for filename in tqdm.tqdm(os.listdir(folder), desc=folder):\n",
    "            songname = os.path.join(folder, filename)\n",
    "            y, sr = librosa.load(songname, mono=True)\n",
    "            rms = librosa.feature.rms(y=y)\n",
    "            chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "            spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "            spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "            rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "            zcr = librosa.feature.zero_crossing_rate(y)\n",
    "            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=N_MFCCS)\n",
    "            \n",
    "            feature_row_data = [np.mean(chroma_stft), np.mean(rms), np.mean(spec_cent), np.mean(spec_bw), np.mean(rolloff), np.mean(zcr)]\n",
    "            for e in mfcc:\n",
    "                feature_row_data.append(np.mean(e))\n",
    "            if folder == \"train\":\n",
    "                feature_row_data.append(bool(labeled_dataset[labeled_dataset[\"Filename\"] == filename][\"Label\"].values[0]))\n",
    "            features.loc[filename] = pd.Series(feature_row_data, index=columns)\n",
    "        features.to_csv(f\"{folder}_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8d5ea",
   "metadata": {},
   "source": [
    "## Обработка датасета и разделение на тренировочную и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b394888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_dataset.csv\", index_col=0)\n",
    "X = df.drop(columns=[\"label\"])\n",
    "y = df[\"label\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "289a3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "        \n",
    "    def __init__(self, features, labels, device=torch.device(\"cpu\")):\n",
    "        self.features = torch.tensor(features.values, dtype = torch.float32).to(device)\n",
    "        self.labels = torch.tensor(labels.values, dtype = torch.float32).to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.features[ind], self.labels[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43f7185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "device = torch.device(\"mps\") \n",
    "train_dataset = MyDataset(x_train, y_train, device)\n",
    "test_dataset = MyDataset(x_test, y_test, device)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1024, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6718c",
   "metadata": {},
   "source": [
    "## Архитектура нашей нейронной сети и ее обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "43c860d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecognizeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RecognizeNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(6 + N_MFCCS, 100)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(100, 200)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(200, 100)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(100, 50)\n",
    "        self.act4 = nn.ReLU()\n",
    "        self.layer5 = nn.Linear(50, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        #self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.act3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.act4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56dcd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecognizeNet()\n",
    "model.to(device)\n",
    "total_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75c66a49",
   "metadata": {
    "scrolled": true
   },
>>>>>>> main
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "train: 100%|██████████| 8803/8803 [05:12<00:00, 28.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving train...\n",
      "train: audios_cut=4376, audios_padded=4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test: 100%|██████████| 2870/2870 [01:57<00:00, 24.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving test...\n",
      "test: audios_cut=5813, audios_padded=5860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
=======
      "Epoch [1000/2000], Loss: 0.0000, Accuracy: 65.48%: 100%|██████████| 1000/1000 [05:02<00:00,  3.31it/s]\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "audio_length = round(AUDIO_TIME_SECONDS * SAMPLE_RATE)\n",
    "for folder in [\"train\", \"test\"]:\n",
    "    audios_cut = 0\n",
    "    audios_padded = 0\n",
    "    columns = (header if folder == \"test\" else header + \" label\").split()\n",
    "    for filename in tqdm.tqdm(os.listdir(folder), desc=folder):\n",
    "        feature_row_data = []\n",
    "        songname = os.path.join(folder, filename)\n",
    "        y, sr = librosa.load(songname, mono=True)\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "        if len(y) > audio_length: \n",
    "            audios_cut += 1\n",
    "            y = y[:audio_length]\n",
    "        else:\n",
    "            y = np.pad(y, (0, audio_length - len(y)), constant_values=0)\n",
    "            audios_padded += 1\n",
    "        mel_df = pd.DataFrame(librosa.feature.melspectrogram(y=y))\n",
    "        if folder == \"train\":\n",
    "            mel_df[\"Label\"] = bool(labeled_dataset[labeled_dataset[\"Filename\"] == filename][\"Label\"].values[0])\n",
    "        mel_df.to_csv(f\"{folder}_data/{filename}_mel.csv\")\n",
    "    print(f\"saving {folder}...\")        \n",
    "    print(f\"{folder}: {audios_cut=}, {audios_padded=}\")"
=======
    "total_step = len(train_loader)\n",
    "epochs = 1000\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "pbar = tqdm.tqdm(range(epochs))\n",
    "for epoch in pbar:\n",
    "    for i, batch in enumerate(train_loader):\n",
    "\n",
    "        x, y = batch\n",
    "        preds = model(x)\n",
    "\n",
    "        loss = loss_fn(preds, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total = y.size(0)\n",
    "        predicted = (torch.flatten((preds.data > 0.5)))\n",
    "        true = y\n",
    "        correct = (predicted == true).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "    total_epochs += 1\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        pbar.set_description('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "                .format(total_epochs, (total_epochs // epochs + 1) * epochs, loss.item(),\n",
    "                        (correct / total) * 100))"
>>>>>>> main
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db8d5ea",
   "metadata": {},
   "source": [
    "## Loading dataset and splitting into train/test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
   "id": "3b394888",
=======
   "execution_count": 62,
   "id": "ad5709e7",
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "100%|██████████| 8803/8803 [00:39<00:00, 224.84it/s]\n"
=======
      "Test Accuracy of the model on the test data: 63.7137989778535 %\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"mps\")\n",
    "X = []\n",
    "y = []\n",
    "for mel in tqdm.tqdm(os.listdir(\"train_data\")):    \n",
    "    df = pd.read_csv(os.path.join(\"train_data\", mel))\n",
    "    X.append(df.drop(\"Label\", axis=1).values)\n",
    "    y.append(df[\"Label\"].values[0]) # \"Label\" is filled with True for compatibility, but we need only one value.\n",
    "X = torch.tensor(X).unsqueeze(1)\n",
    "y = torch.tensor(y).unsqueeze(1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "289a3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
=======
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in test_loader:\n",
    "        y_pred = model(x)\n",
    "        predicted = (torch.flatten((preds.data > 0.5)))\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
>>>>>>> main
    "\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        return self.features[ind], self.labels[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43f7185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(x_train, y_train)\n",
    "test_dataset = MyDataset(x_test, y_test)\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb6718c",
   "metadata": {},
   "source": [
    "## Архитектура нашей нейронной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "43c860d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_conv2d_out_shape(hin,win,conv: nn.Conv2d,pool=2):\n",
    "    # get conv arguments\n",
    "    kernel_size=conv.kernel_size\n",
    "    stride=conv.stride\n",
    "    padding=conv.padding\n",
    "    dilation=conv.dilation\n",
    "    if not isinstance(padding, tuple):\n",
    "        padding = (padding,padding)\n",
    "    if not isinstance(stride, tuple):\n",
    "        stride = (stride,stride)\n",
    "    if not isinstance(dilation, tuple):\n",
    "        dilation = (dilation,dilation)\n",
    "    if not isinstance(kernel_size, tuple):\n",
    "        kernel_size = (kernel_size,kernel_size)\n",
    "    hout=np.floor((hin \n",
    "                   + 2*padding[0] \n",
    "                   - dilation[0] * (kernel_size[0]-1) - 1)\n",
    "                   / stride[0] + 1)\n",
    "    wout=np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
    "\n",
    "    if pool:\n",
    "        hout/=pool\n",
    "        wout/=pool\n",
    "    return int(hout),int(wout)\n",
    "\n",
    "\n",
    "class MelConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MelConvNet, self).__init__()\n",
    "        input_shape = (128, 200)\n",
    "        out_ch = 3\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, out_ch, kernel_size=(3,3), stride=(1,1), padding=(0,0))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        width, height = find_conv2d_out_shape(input_shape[0], input_shape[1], self.conv1)\n",
    "         \n",
    "        # self.conv2 = nn.Conv2d(16, out_ch, (3,3), (1,1), (0,0))\n",
    "        # self.pool2 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        # width, height = find_conv2d_out_shape(width, height, self.conv2)\n",
    "         \n",
    "        # self.conv3 = nn.Conv2d(16, out_ch, (3,3), (1,1), (0,0))\n",
    "        # self.pool3 = nn.MaxPool2d(kernel_size=(2,2))\n",
    "        # width, height = find_conv2d_out_shape(width, height, self.conv3)\n",
    "\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc = nn.Linear(width * height * out_ch, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "         \n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "         \n",
    "        # x = self.conv2(x)\n",
    "        # x = self.pool2(x)\n",
    "         \n",
    "        # x = self.conv3(x)\n",
    "        # x = self.pool3(x)\n",
    "         \n",
    "        x = self.flatten(x)\n",
    "         \n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8ddc2",
   "metadata": {},
   "source": [
    "## и ее обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "56dcd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MelConvNet()\n",
    "model.to(device)\n",
    "total_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "75c66a49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loader: val. Accuracy: 52.70%:   2%|▏         | 19/1000 [01:50<1:35:01,  5.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERFITTED AT EPOCH 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n",
    "loss_fn = nn.BCELoss()\n",
    "loaders = {\"train\": train_loader, \"val\": test_loader}\n",
    "accuracy = {\"train\": [], \"val\": []}\n",
    "val_progress = 0 # track accuracy improvement or degradation\n",
    "VAL_DECREASE_BREAK = -3 # when decreased x times, model overfitted, stop training\n",
    "model.train()\n",
    "pbar = tqdm.tqdm(range(epochs))\n",
    "for epoch in pbar:\n",
    "    for key, loader in loaders.items():\n",
    "        epoch_correct = 0\n",
    "        epoch_all = 0\n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            if key == \"train\":\n",
    "                model.train()\n",
    "                optimizer.zero_grad()\n",
    "                outp = model(x_batch)\n",
    "                loss = loss_fn(outp, y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            else:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    outp = model(x_batch)\n",
    "            total = y_batch.size(0)\n",
    "            predicted = outp.data >= 0.5\n",
    "            correct = (predicted == y_batch).sum().item()\n",
    "            correct = sum(predicted == y_batch)\n",
    "            all_ = len(outp)\n",
    "            epoch_correct += correct.item()\n",
    "            epoch_all += all_\n",
    "        #scheduler.step()\n",
    "        pbar.set_description(f\"Loader: {key}. Accuracy: {epoch_correct/epoch_all:.2%}\")\n",
    "        accuracy[key].append(epoch_correct/epoch_all)\n",
    "        if key == \"val\" and len(accuracy[key]) >= 2:\n",
    "            if val_progress > 0:\n",
    "                val_progress = 0\n",
    "            if accuracy[key][-1] > accuracy[key][-2]:\n",
    "                val_progress += 1\n",
    "            else:\n",
    "                val_progress -= 1\n",
    "            if val_progress <= VAL_DECREASE_BREAK:\n",
    "                print(f\"OVERFITTED AT EPOCH {epoch}\")\n",
    "                break\n",
    "    else: # if not broken with val decrease excision\n",
    "        total_epochs += 1\n",
    "        continue\n",
    "    break\n",
    "[plt.plot(accuracies, label=name) for name, accuracies in accuracy.items()]\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c33b8",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf09cc",
   "metadata": {},
   "source": [
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "id": "3f61aaf3",
=======
   "execution_count": 63,
   "id": "938a10ca",
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scoring = []\n",
    "paths = []\n",
    "for path in tqdm.tqdm(os.listdir(\"test_data\")):   \n",
    "    paths.append(path) \n",
    "    df = pd.read_csv(os.path.join(\"test_data\", path))\n",
    "    data_scoring.append(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c9de5c",
   "metadata": {},
   "source": [
    "## Submiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "938a10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting..\n"
     ]
    }
   ],
   "source": [
    "data_scoring = torch.tensor(data_scoring, dtype=torch.float32).to(device)\n",
    "sample_submission = pd.read_csv(\"test (1).csv\")\n",
    "print(\"predicting..\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    results = model(data_scoring) >= 0.5\n",
    "\n",
    "submission = pd.DataFrame({\"Filename\": paths, \"Label\": results.squeeze(1).to(\"cpu\")})\n",
    "submission = submission.sort_values(by=\"Filename\")\n",
    "sample_submission = sample_submission.sort_values(by=\"Filename\")\n",
    "sample_submission[\"Label\"] = submission[\"Label\"]\n",
    "sample_submission = sample_submission.sort_index()\n",
    "sample_submission.to_csv(\"submission.csv\", index=False, header=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
